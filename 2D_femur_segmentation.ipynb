{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5eTn_lcrrKA",
        "outputId": "6e548504-f9c9-49e2-b424-86f3f293231a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.25.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-python-headless\n",
        "!pip install albumentations\n",
        "!pip install nibabel\n",
        "!pip install matplotlib\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy_NhT4nr0dT"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFfiTRKSr7J5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed58d6e-a7ff-495a-e483-750d0f53b75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_Amb-QM5uMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f92dd8-2bc3-4899-f8fc-928e3b3a6479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5L2CfTgtg1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd19de5-04c0-4b02-ba13-4d13c52e65f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRRD file number 1 is being converted...\n",
            "NRRD file number 2 is being converted...\n",
            "NRRD file number 3 is being converted...\n",
            "NRRD file number 4 is being converted...\n",
            "NRRD file number 5 is being converted...\n",
            "NRRD file number 6 is being converted...\n",
            "NRRD file number 7 is being converted...\n",
            "NRRD file number 8 is being converted...\n",
            "NRRD file number 9 is being converted...\n",
            "NRRD file number 10 is being converted...\n",
            "NRRD file number 11 is being converted...\n",
            "NRRD file number 12 is being converted...\n",
            "NRRD file number 13 is being converted...\n",
            "NRRD file number 14 is being converted...\n",
            "NRRD file number 15 is being converted...\n",
            "NRRD file number 16 is being converted...\n",
            "NRRD file number 17 is being converted...\n",
            "NRRD file number 18 is being converted...\n",
            "NRRD file number 19 is being converted...\n",
            "NRRD file number 20 is being converted...\n",
            "NRRD file number 21 is being converted...\n",
            "NRRD file number 22 is being converted...\n",
            "NRRD file number 23 is being converted...\n",
            "NRRD file number 24 is being converted...\n",
            "NRRD file number 25 is being converted...\n",
            "NRRD file number 26 is being converted...\n",
            "NRRD file number 27 is being converted...\n",
            "NRRD file number 28 is being converted...\n",
            "NRRD file number 29 is being converted...\n",
            "NRRD file number 30 is being converted...\n",
            "NRRD file number 31 is being converted...\n",
            "NRRD file number 32 is being converted...\n",
            "NRRD file number 33 is being converted...\n",
            "NRRD file number 34 is being converted...\n",
            "NRRD file number 35 is being converted...\n",
            "NRRD file number 36 is being converted...\n",
            "NRRD file number 37 is being converted...\n",
            "NRRD file number 38 is being converted...\n",
            "NRRD file number 39 is being converted...\n",
            "NRRD file number 40 is being converted...\n",
            "\n",
            "There are 11622 number of images in the train set\n",
            "There are 3874 number of images in the validation set\n",
            "There are 3874 number of images in the test set\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "class CustomSegmentationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root, transformations=None):\n",
        "        im_nrrd_paths = sorted(glob.glob(f\"{root}/Images/*.nrrd\"))\n",
        "        gt_nrrd_paths = sorted(glob.glob(f\"{root}/GoldStandard/*.nrrd\"))\n",
        "\n",
        "        numeri_lista = []\n",
        "\n",
        "        for percorso in gt_nrrd_paths:\n",
        "            # Estrai il numero alla fine del percorso del file vicino alla 'L'\n",
        "            numero = int(percorso.split('/')[-1].split('_')[0][1:])\n",
        "            numeri_lista.append(numero)\n",
        "\n",
        "\n",
        "        indice_da_rimuovere = numeri_lista.index(442)\n",
        "\n",
        "        # Rimuovi l'elemento corrispondente all'indice trovato da gt_paths\n",
        "        elemento_da_rimuovere = gt_nrrd_paths[indice_da_rimuovere]\n",
        "        gt_nrrd_paths.remove(elemento_da_rimuovere)\n",
        "\n",
        "        # images_path.append(im_nrrd_paths)\n",
        "        # gt_paths.append(gt_nrrd_paths)\n",
        "        self.ims, self.gts, self.orientation = self.get_slices(im_nrrd_paths, gt_nrrd_paths)\n",
        "        self.transformations = transformations\n",
        "        self.n_cls = 2\n",
        "\n",
        "        assert len(self.ims) == len(self.gts) == len(self.orientation)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        im, gt, orientation = self.ims[idx], self.gts[idx], self.orientation[idx]\n",
        "        if self.transformations:\n",
        "            im, gt = self.apply_transformations(im, gt)\n",
        "\n",
        "        # For visualization purposes\n",
        "        im = self.preprocess_im(im)\n",
        "        # For the cases when label equals to 2; to avoid CE Loss error\n",
        "        gt[gt > 1] = 1\n",
        "\n",
        "        return im.float(), gt.unsqueeze(0).long(), orientation\n",
        "\n",
        "    def apply_transformations(self, im, gt): transformed = self.transformations(image = im, mask = gt); return transformed[\"image\"], transformed[\"mask\"]\n",
        "\n",
        "    def get_slices(self, im_nrrd_paths, gt_nrrd_paths):\n",
        "        ims, gts, orientation = [], [], []\n",
        "\n",
        "        for index, (im_nrrd, gt_nrrd) in enumerate(zip(im_nrrd_paths, gt_nrrd_paths)):\n",
        "            print(f\"NRRD file number {index + 1} is being converted...\")\n",
        "            nrrd_im_data, nrrd_gt_data = self.read_nrrd(im_nrrd, gt_nrrd)\n",
        "\n",
        "            # Slicing in axial, coronal, and sagittal directions\n",
        "            for axis in range(3):\n",
        "                for idx in range(nrrd_im_data.shape[axis]):\n",
        "                    if axis == 0:\n",
        "                        im_slice = nrrd_im_data[idx, :, :]\n",
        "                        gt_slice = nrrd_gt_data[idx, :, :]\n",
        "                        orient = 0\n",
        "                    elif axis == 1:\n",
        "                        im_slice = nrrd_im_data[:, idx, :]\n",
        "                        gt_slice = nrrd_gt_data[:, idx, :]\n",
        "                        orient = 1\n",
        "                    elif axis == 2:\n",
        "                        im_slice = nrrd_im_data[:, :, idx]\n",
        "                        gt_slice = nrrd_gt_data[:, :, idx]\n",
        "                        orient = 2\n",
        "\n",
        "                    if len(np.unique(gt_slice)) == 2:\n",
        "                        # Resize image and mask to 256x256\n",
        "                        im_resized = sitk.GetArrayFromImage(sitk.Resample(sitk.GetImageFromArray(im_slice), (256, 256)))\n",
        "                        gt_resized = sitk.GetArrayFromImage(sitk.Resample(sitk.GetImageFromArray(gt_slice), (256, 256)))\n",
        "                        ims.append(im_resized)\n",
        "                        gts.append(gt_resized)\n",
        "                        orientation.append((index, orient))\n",
        "\n",
        "        return ims, gts, orientation\n",
        "\n",
        "    def read_nrrd(self, im_path, gt_path):\n",
        "        im_data = sitk.ReadImage(im_path)\n",
        "        gt_data = sitk.ReadImage(gt_path)\n",
        "        return sitk.GetArrayFromImage(im_data), sitk.GetArrayFromImage(gt_data)\n",
        "\n",
        "    def preprocess_im(self, im):\n",
        "        # Push background value of -3024 to -1000\n",
        "        im[im == -3024] = -1000\n",
        "\n",
        "        # Min-max scaling\n",
        "        min_val = torch.min(im)\n",
        "        max_val = torch.max(im)\n",
        "\n",
        "        # Ensure the min value is not equal to the max value to avoid division by zero\n",
        "        if min_val != max_val:\n",
        "            im = (im - min_val) / (max_val - min_val)\n",
        "        else:\n",
        "            im = torch.zeros_like(im)\n",
        "\n",
        "        return im\n",
        "# Example usage to plot an image before DataLoader creation\n",
        "def get_dls(root, transformations, bs, split = [0.6, 0.2, 0.2], ns = 4):\n",
        "\n",
        "    #assert sum(split) == 1., \"Sum of the split must be exactly 1\"\n",
        "\n",
        "    ds = CustomSegmentationDataset(root = root, transformations = transformations)\n",
        "    n_cls = ds.n_cls\n",
        "\n",
        "    tr_len = int(len(ds) * split[0])\n",
        "    val_len = int(len(ds) * split[1])\n",
        "    test_len = len(ds) - (tr_len + val_len)\n",
        "\n",
        "    ds_len = len(ds)\n",
        "    indices = list(range(ds_len))\n",
        "\n",
        "    # Define the lengths for the splits\n",
        "    tr_len = int(0.6 * ds_len)  # 60% for training\n",
        "    val_len = int(0.2 * ds_len)  # 20% for validation\n",
        "    test_len = ds_len - tr_len - val_len  # Remaining 20% for testing\n",
        "\n",
        "    # Split indices\n",
        "    tr_indices = indices[:tr_len]\n",
        "    val_indices = indices[tr_len:tr_len + val_len]\n",
        "    test_indices = indices[tr_len + val_len:]\n",
        "\n",
        "    # Create subsets\n",
        "    tr_ds = Subset(ds, tr_indices)\n",
        "    val_ds = Subset(ds, val_indices)\n",
        "    test_ds = Subset(ds, test_indices)\n",
        "\n",
        "    print(f\"\\nThere are {len(tr_ds)} number of images in the train set\")\n",
        "    print(f\"There are {len(val_ds)} number of images in the validation set\")\n",
        "    print(f\"There are {len(test_ds)} number of images in the test set\\n\")\n",
        "    # Get dataloaders\n",
        "    tr_dl  = DataLoader(dataset = tr_ds, batch_size = bs, shuffle = True, num_workers = ns)\n",
        "    val_dl = DataLoader(dataset = val_ds, batch_size = bs, shuffle = False, num_workers = ns)\n",
        "    test_dl = DataLoader(dataset = test_ds, batch_size = 1, shuffle = False, num_workers = ns)\n",
        "\n",
        "    return ds, tr_dl, val_dl, test_dl, n_cls\n",
        "\n",
        "root = r\"/content/drive/MyDrive/Runnare_fusco/NewPatients/NewPatients\"\n",
        "mean, std, im_h, im_w = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 256, 256\n",
        "trans = A.Compose([\n",
        "    ToTensorV2(transpose_mask=True),\n",
        "])\n",
        "ds, tr_dl, val_dl, test_dl, n_cls = get_dls(root = root, transformations = trans, bs = 16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOW3theUfWo6",
        "outputId": "d7b68399-5b13-465b-e4cf-9c77ff3d25fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.5.82)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=74ecbc7c48bdabf3c370b0e20f8fd42d659c9023fdea9013f3033544a589d991\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=7c1663fef342cdc1dec8bb7d93d8cdcfd8e8423e5954a7a6a7f192bb4ac12710\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI8rRHkg6NUX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def plot(rows, cols, count, im, gt = None, title = \"Original Image\"):\n",
        "\n",
        "    plt.subplot(rows, cols, count)\n",
        "    plt.imshow(im.squeeze(0).float()) if gt else plt.imshow((im * 255).cpu().permute(1, 2, 0).numpy().astype(\"uint8\") * 255)\n",
        "    plt.axis(\"off\"); plt.title(title)\n",
        "\n",
        "    return count + 1\n",
        "\n",
        "def visualize(ds, n_ims):\n",
        "\n",
        "    plt.figure(figsize = (25, 20))\n",
        "    rows = n_ims // 4; cols = n_ims // rows\n",
        "    count = 1\n",
        "    indices = [random.randint(0, len(ds) - 1) for _ in range(n_ims)]\n",
        "\n",
        "    for idx, index in enumerate(indices):\n",
        "\n",
        "        if count == n_ims + 1: break\n",
        "\n",
        "        im, gt,_ = ds[index]\n",
        "\n",
        "        # First Plot\n",
        "        count = plot(rows, cols, count, im = im)\n",
        "\n",
        "        # Second Plot\n",
        "        count = plot(rows, cols, count, im = gt.squeeze(0), gt = True, title = \"GT Mask\")\n",
        "\n",
        "# visualize(tr_dl.dataset, n_ims = 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G-iKHYfV6Tiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5685d928-94c5-4889-8c16-1abf9f47d00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.0+cu121)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: timm==0.9.2 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (12.5.82)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 50"
      ],
      "metadata": {
        "id": "I5FXVlcX-zek"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff7WVOHH6Sjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86eadfa3-964b-4e8e-f95a-5fda2d562530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 116MB/s]\n"
          ]
        }
      ],
      "source": [
        "import segmentation_models_pytorch as smp, time\n",
        "model= smp.Unet(\n",
        "    encoder_name='resnet50',\n",
        "    encoder_weights=\"imagenet\",\n",
        "    encoder_depth=5,\n",
        "    in_channels=1,\n",
        "    classes=n_cls,\n",
        "    activation=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1m_WMAB7Evv"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n",
        "\n",
        "class Metrics():\n",
        "\n",
        "    def __init__(self, pred, gt, loss_fn, eps = 1e-10, n_cls = 2):\n",
        "\n",
        "        self.pred, self.gt = torch.argmax(pred, dim = 1) > 0, gt # (batch, width, height)\n",
        "        self.loss_fn, self.eps, self.n_cls, self.pred_, self.device = loss_fn, eps, n_cls, pred, device\n",
        "\n",
        "    def to_contiguous(self, inp): return inp.contiguous().view(-1)\n",
        "\n",
        "    def PA(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            match = torch.eq(self.pred, self.gt).int()\n",
        "\n",
        "        return float(match.sum()) / float(match.numel())\n",
        "\n",
        "    def mIoU(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred, gt = self.to_contiguous(self.pred), self.to_contiguous(self.gt)\n",
        "\n",
        "            iou_per_class = []\n",
        "\n",
        "            for c in range(self.n_cls):\n",
        "\n",
        "                match_pred = pred == c\n",
        "                match_gt   = gt == c\n",
        "\n",
        "                if match_gt.long().sum().item() == 0: iou_per_class.append(np.nan)\n",
        "\n",
        "                else:\n",
        "\n",
        "                    intersect = torch.logical_and(match_pred, match_gt).sum().float().item()\n",
        "                    union = torch.logical_or(match_pred, match_gt).sum().float().item()\n",
        "\n",
        "                    iou = (intersect + self.eps) / (union + self.eps)\n",
        "                    iou_per_class.append(iou)\n",
        "\n",
        "            return np.nanmean(iou_per_class)\n",
        "\n",
        "    def loss(self): return self.loss_fn(self.pred_, self.gt.squeeze(1))\n",
        "\n",
        "def tic_toc(start_time = None): return time.time() if start_time == None else time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a7GT3Xh7uk5"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "mD3IgpDLzx3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvg-5gqH7dOo",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ae3684-3841-4836-ee68-8a64d45d072b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training process...\n",
            "Epoch 1 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/727 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "100%|██████████| 727/727 [03:57<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:27<00:00,  8.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 1 train process results: \n",
            "\n",
            "Train Time         -> 265.444 secs\n",
            "Train Loss         -> 0.065\n",
            "Train PA           -> 0.934\n",
            "Train IoU          -> 0.893\n",
            "Validation Loss    -> 0.015\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.931\n",
            "\n",
            "Loss decreased from inf to 0.015!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [03:57<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:27<00:00,  8.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process results: \n",
            "\n",
            "Train Time         -> 264.222 secs\n",
            "Train Loss         -> 0.011\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.950\n",
            "Validation Loss    -> 0.015\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.936\n",
            "\n",
            "Loss did not decrease for 1 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [03:57<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:27<00:00,  8.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process results: \n",
            "\n",
            "Train Time         -> 264.525 secs\n",
            "Train Loss         -> 0.008\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.959\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.952\n",
            "\n",
            "Loss decreased from 0.015 to 0.009!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [03:57<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:26<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process results: \n",
            "\n",
            "Train Time         -> 264.182 secs\n",
            "Train Loss         -> 0.006\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.969\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.988\n",
            "Validation IoU     -> 0.955\n",
            "\n",
            "Loss decreased from 0.009 to 0.009!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [03:57<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:27<00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process results: \n",
            "\n",
            "Train Time         -> 265.123 secs\n",
            "Train Loss         -> 0.004\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.975\n",
            "Validation Loss    -> 0.012\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.945\n",
            "\n",
            "Loss did not decrease for 2 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Train process is completed in 22.072 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def train(model, tr_dl, val_dl, loss_fn, opt, device, epochs, save_prefix, threshold = 0.00, save_path = \"saved_models\"):\n",
        "\n",
        "    tr_loss, tr_pa, tr_iou = [], [], []\n",
        "    val_loss, val_pa, val_iou = [], [], []\n",
        "    tr_len, val_len = len(tr_dl), len(val_dl)\n",
        "    best_loss, decrease, not_improve, early_stop_threshold = np.inf, 1, 0, 5\n",
        "    os.makedirs(save_path, exist_ok = True)\n",
        "\n",
        "    model.to(device)\n",
        "    train_start = tic_toc()\n",
        "    print(\"Start training process...\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        tic = tic_toc()\n",
        "        tr_loss_, tr_iou_, tr_pa_ = 0, 0, 0\n",
        "\n",
        "        model.train()\n",
        "        print(f\"Epoch {epoch} train process is started...\")\n",
        "        for idx, batch in enumerate(tqdm(tr_dl)):\n",
        "            ims, gts,_ = batch\n",
        "            ims, gts = ims.to(device), gts.to(device).long()\n",
        "\n",
        "            preds = model(ims)\n",
        "\n",
        "            met = Metrics(preds, gts, loss_fn, n_cls = n_cls)\n",
        "            loss_ = met.loss().requires_grad_()\n",
        "\n",
        "            tr_iou_ += met.mIoU()\n",
        "            tr_pa_ += met.PA()\n",
        "            tr_loss_ += loss_.item()\n",
        "\n",
        "            loss_.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        print(f\"Epoch {epoch} validation process is started...\")\n",
        "        model.eval()\n",
        "        val_loss_, val_iou_, val_pa_ = 0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, batch in enumerate(tqdm(val_dl)):\n",
        "\n",
        "                ims, gts,_ = batch\n",
        "                ims, gts = ims.to(device), gts.to(device)\n",
        "\n",
        "                preds = model(ims)\n",
        "\n",
        "                met = Metrics(preds, gts, loss_fn, n_cls = n_cls)\n",
        "\n",
        "                val_loss_ += met.loss().item()\n",
        "                val_iou_ += met.mIoU()\n",
        "                val_pa_ += met.PA()\n",
        "\n",
        "        print(f\"Epoch {epoch} train process is completed.\")\n",
        "\n",
        "        tr_loss_ /= tr_len\n",
        "        tr_iou_ /= tr_len\n",
        "        tr_pa_ /= tr_len\n",
        "\n",
        "        val_loss_ /= val_len\n",
        "        val_iou_ /=  val_len\n",
        "        val_pa_ /=   val_len\n",
        "\n",
        "        print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "        print(f\"\\nEpoch {epoch} train process results: \\n\")\n",
        "        print(f\"Train Time         -> {tic_toc(tic):.3f} secs\")\n",
        "        print(f\"Train Loss         -> {tr_loss_:.3f}\")\n",
        "        print(f\"Train PA           -> {tr_pa_:.3f}\")\n",
        "        print(f\"Train IoU          -> {tr_iou_:.3f}\")\n",
        "        print(f\"Validation Loss    -> {val_loss_:.3f}\")\n",
        "        print(f\"Validation PA      -> {val_pa_:.3f}\")\n",
        "        print(f\"Validation IoU     -> {val_iou_:.3f}\\n\")\n",
        "\n",
        "        tr_loss.append(tr_loss_)\n",
        "        tr_iou.append(tr_iou_)\n",
        "        tr_pa.append(tr_pa_)\n",
        "\n",
        "        val_loss.append(val_loss_)\n",
        "        val_iou.append(val_iou_)\n",
        "        val_pa.append(val_pa_)\n",
        "\n",
        "        if best_loss > (val_loss_ + threshold):\n",
        "            print(f\"Loss decreased from {best_loss:.3f} to {val_loss_:.3f}!\")\n",
        "            best_loss = val_loss_\n",
        "            decrease += 1\n",
        "            if decrease % 2 == 0:\n",
        "                print(\"Saving the model with the best loss value...\")\n",
        "                torch.save(model, f\"{save_path}/{save_prefix}_best_model.pt\")\n",
        "\n",
        "        else:\n",
        "\n",
        "            not_improve += 1\n",
        "            best_loss = val_loss_\n",
        "            print(f\"Loss did not decrease for {not_improve} epoch(s)!\")\n",
        "            if not_improve == early_stop_threshold:\n",
        "                print(f\"Stopping training process becuase loss value did not decrease for {early_stop_threshold} epochs!\")\n",
        "                break\n",
        "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
        "\n",
        "    print(f\"Train process is completed in {(tic_toc(train_start)) / 60:.3f} minutes.\")\n",
        "\n",
        "    return {\"tr_loss\": tr_loss, \"tr_iou\": tr_iou, \"tr_pa\": tr_pa,\n",
        "            \"val_loss\": val_loss, \"val_iou\": val_iou, \"val_pa\" : val_pa}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history = train(model = model, tr_dl = tr_dl, val_dl = val_dl,\n",
        "                 loss_fn = loss_fn, opt = optimizer, device = device,\n",
        "                 epochs = EPOCHS, save_prefix = \"UnetResnet50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-l0UczfArLL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class Plot():\n",
        "\n",
        "    def __init__(self, res):\n",
        "\n",
        "        self.res = res\n",
        "\n",
        "        self.visualize(metric1 = \"tr_iou\", metric2 = \"val_iou\", label1 = \"Train IoU\",\n",
        "                  label2 = \"Validation IoU\", title = \"Mean Intersection Over Union Learning Curve\", ylabel = \"mIoU Score\")\n",
        "\n",
        "        self.visualize(metric1 = \"tr_pa\", metric2 = \"val_pa\", label1 = \"Train PA\",\n",
        "                  label2 = \"Validation PA\", title = \"Pixel Accuracy Learning Curve\", ylabel = \"PA Score\")\n",
        "\n",
        "        self.visualize(metric1 = \"tr_loss\", metric2 = \"val_loss\", label1 = \"Train Loss\",\n",
        "                  label2 = \"Validation Loss\", title = \"Loss Learning Curve\", ylabel = \"Loss Value\")\n",
        "\n",
        "    def plot(self, metric, label): plt.plot(self.res[metric], label = label)\n",
        "\n",
        "    def decorate(self, ylabel, title): plt.title(title); plt.xlabel(\"Epochs\"); plt.ylabel(ylabel); plt.legend(); plt.show()\n",
        "\n",
        "    def visualize(self, metric1, metric2, label1, label2, title, ylabel):\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        self.plot(metric1, label1); self.plot(metric2, label2)\n",
        "        self.decorate(ylabel, title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNhk9D3mA9Qo"
      },
      "outputs": [],
      "source": [
        "def inference(dl, model, device, n_ims = 60):\n",
        "\n",
        "    cols = n_ims // 3; rows = n_ims // cols\n",
        "\n",
        "    count = 1\n",
        "    ims, gts, preds = [], [], []\n",
        "    for idx, data in enumerate(dl):\n",
        "        im, gt = data\n",
        "\n",
        "        # Get predicted mask\n",
        "        with torch.no_grad(): pred = torch.argmax(model(im.to(device)), dim = 1)\n",
        "        ims.append(im); gts.append(gt); preds.append(pred)\n",
        "\n",
        "    plt.figure(figsize = (15, 30))\n",
        "    for idx, (im, gt, pred) in enumerate(zip(ims, gts, preds)):\n",
        "        if idx == cols: break\n",
        "        # First plot\n",
        "        count = plot(cols, rows, count, im.squeeze(0))\n",
        "\n",
        "        # Second plot\n",
        "        count = plot(cols, rows, count, im = gt.squeeze(0), gt = True, title = \"Ground Truth\")\n",
        "\n",
        "        # Third plot\n",
        "        count = plot(cols, rows, count, im = pred, title = \"Predicted Mask\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D):\n",
        "  print(\"The MIOU for the segmentation over the test set resulted in:\")\n",
        "  print(np.round(np.array(miou_test).mean(),3), \" +\\- \",np.round(np.array(miou_test).std(),3) )\n",
        "  print()\n",
        "  print(\"The MIOU 3D for the segmentation over the test set resulted in:\")\n",
        "  print(np.round(np.array(list_mioU3D).mean(),3), \" +\\- \",np.round(np.array(list_mioU3D).std(),3) )\n",
        "  print()\n",
        "  print(\"The Dicescore for the segmentation over the test set resulted in:\")\n",
        "  print(np.round(np.array(dicescores).mean(),3), \" +\\- \", np.round(np.array(dicescores).std(),3))\n",
        "  print()\n",
        "  print(\"The Dicescore 3D for the segmentation over the test set resulted in:\")\n",
        "  print(np.round(np.array(list_dice3D).mean(),3), \" +\\- \", np.round(np.array(list_dice3D).std(),3))\n",
        "  print()\n",
        "  print(\"The volume similarity for the segmentation over the test set resulted in:\")\n",
        "  print(np.round(np.array(volume_similarities).mean(),3), \" +\\- \", np.round(np.array(volume_similarities).std(),3))\n",
        "  print()\n",
        "\n",
        "  print(\"The volume similarity abs for the segmentation over the test set resulted in:\")\n",
        "  print(np.round(np.array(vol_sim_abs).mean(),3), \" +\\- \", np.round(np.array(vol_sim_abs).std(),3))\n",
        "  print()\n",
        "\n",
        "  print()\n",
        "  print(\"The time needed for the segmentation of 8 3D images is:\")\n",
        "  print(np.round(execution_time,2), \"seconds.\")\n"
      ],
      "metadata": {
        "id": "2tj0nfovKA3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "# Suppress the specific warning about DataLoader workers\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*DataLoader.*max number of worker.*\")\n",
        "def calculate_volume_similarity(gtMask,predMask):\n",
        "    gtMask = np.array(gtMask)\n",
        "    predMask = np.array(predMask)\n",
        "    tp = np.sum((gtMask == 1) & (predMask == 1))\n",
        "    fp = np.sum((gtMask == 0) & (predMask == 1))\n",
        "    fn = np.sum((gtMask == 1) & (predMask == 0))\n",
        "    numerator = fn - fp\n",
        "    numerator2 = abs(numerator)\n",
        "    denominator = 2*tp + fp + fn\n",
        "    if denominator == 0:\n",
        "      return 0,0\n",
        "    volume_similarity = 1 - (numerator/denominator)\n",
        "    volume_similarityabs = 1 - (numerator2/denominator)\n",
        "    return volume_similarity, volume_similarityabs\n",
        "\n",
        "def calculateScores(gtMask, predMask):\n",
        "    # Convert to NumPy arrays if they aren't already\n",
        "    gtMask = np.array(gtMask)\n",
        "    predMask = np.array(predMask)\n",
        "\n",
        "    # Calculate the true positives (TP), false positives (FP), and false negatives (FN)\n",
        "    tp = np.sum((gtMask == 1) & (predMask == 1))\n",
        "    fp = np.sum((gtMask == 0) & (predMask == 1))\n",
        "    fn = np.sum((gtMask == 1) & (predMask == 0))\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = tp / (tp + fp + fn)\n",
        "\n",
        "    dice = np.sum(predMask[gtMask==1]) * 2.0 / (np.sum(predMask) + np.sum(gtMask))\n",
        "\n",
        "    return iou, dice\n",
        "\n",
        "\n",
        "\n",
        "def calculate_results(model,test_data):\n",
        "\n",
        "  miou_test = []\n",
        "  dicescores = []\n",
        "  start_time = time.time()\n",
        "  min_iou = 0\n",
        "  current_images = []\n",
        "  current_gt = []\n",
        "  index = -1\n",
        "  volume_similarities = []\n",
        "  volume_similarity_abs = []\n",
        "  list_mioU3D = []\n",
        "  list_dice3D = []\n",
        "  current_axis = -1\n",
        "\n",
        "  for idx, data in enumerate(tqdm(test_data)):\n",
        "      im, gt, orientation = data\n",
        "      new_index, axis = orientation\n",
        "      if axis != current_axis:\n",
        "        if index != -1:  # Ensure it's not the first iteration\n",
        "            vol_sim , vol_sim_abs = calculate_volume_similarity(current_gt, current_images)\n",
        "            volume_similarities.append(vol_sim)\n",
        "            volume_similarity_abs.append(vol_sim_abs)\n",
        "            miou3D, dice3D = calculateScores(current_gt,current_images)\n",
        "            list_mioU3D.append(miou3D)\n",
        "            list_dice3D.append(dice3D)\n",
        "\n",
        "        index = new_index\n",
        "        current_axis = axis\n",
        "        current_images = []\n",
        "        current_gt = []\n",
        "\n",
        "\n",
        "\n",
        "      # Get predicted mask\n",
        "      with torch.no_grad():\n",
        "          pred = torch.argmax(model(im.to(device)), dim=1)\n",
        "\n",
        "      pred = np.array(pred.squeeze(0).cpu())  # Remove batch dimension\n",
        "      gt = np.array(gt.squeeze(0).cpu()[0])\n",
        "\n",
        "      Iou, dice = calculateScores(gt, pred)\n",
        "\n",
        "      current_images.append(pred)\n",
        "      current_gt.append(gt)\n",
        "\n",
        "      miou_test.append(Iou)\n",
        "      dicescores.append(dice)\n",
        "\n",
        "  if current_gt and current_images:\n",
        "          vol_sim , vol_sim_abs = calculate_volume_similarity(current_gt, current_images)\n",
        "          volume_similarities.append(vol_sim)\n",
        "          volume_similarity_abs.append(vol_sim_abs)\n",
        "          miou3D, dice3D = calculateScores(current_gt,current_images)\n",
        "          list_mioU3D.append(miou3D)\n",
        "          list_dice3D.append(dice3D)\n",
        "  end_time = time.time()  # End the timer\n",
        "\n",
        "  execution_time = end_time - start_time\n",
        "  return volume_similarities,volume_similarity_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D\n"
      ],
      "metadata": {
        "id": "ko5qNUU8KC_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_group_averages(scores):\n",
        "    # Convertiamo la lista in un array NumPy per facilitare la manipolazione\n",
        "    scores_array = np.array(scores)\n",
        "\n",
        "    # Calcoliamo la media dei gruppi di tre elementi\n",
        "    num_groups = len(scores_array) // 3\n",
        "    group_averages = []\n",
        "\n",
        "    for i in range(num_groups):\n",
        "        group = scores_array[i*3:(i+1)*3]  # Prendiamo il sottogruppo di tre elementi\n",
        "        average = np.mean(group)  # Calcoliamo la media del gruppo\n",
        "        group_averages.append(average)\n",
        "\n",
        "    return group_averages"
      ],
      "metadata": {
        "id": "I81d2VmoNulJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "volume_similarities,vol_sim_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D = calculate_results(model,test_dl )\n",
        "\n",
        "volume_similarities = calculate_group_averages(volume_similarities)\n",
        "vol_sim_abs = calculate_group_averages(vol_sim_abs)\n",
        "list_mioU3D = calculate_group_averages(list_mioU3D)\n",
        "list_dice3D = calculate_group_averages(list_dice3D)\n",
        "print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr3BnU2IN1Dh",
        "outputId": "512e2e74-30dc-4011-c7b1-dec546891d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3874/3874 [01:25<00:00, 45.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIOU for the segmentation over the test set resulted in:\n",
            "0.897  +\\-  0.145\n",
            "\n",
            "The MIOU 3D for the segmentation over the test set resulted in:\n",
            "0.905  +\\-  0.047\n",
            "\n",
            "The Dicescore for the segmentation over the test set resulted in:\n",
            "0.937  +\\-  0.121\n",
            "\n",
            "The Dicescore 3D for the segmentation over the test set resulted in:\n",
            "0.948  +\\-  0.03\n",
            "\n",
            "The volume similarity for the segmentation over the test set resulted in:\n",
            "1.019  +\\-  0.017\n",
            "\n",
            "The volume similarity abs for the segmentation over the test set resulted in:\n",
            "0.978  +\\-  0.015\n",
            "\n",
            "\n",
            "The time needed for the segmentation of 8 3D images is:\n",
            "85.65 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 34"
      ],
      "metadata": {
        "id": "DvbuxKyN-_Rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbJTeSwn-_Ry"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp, time\n",
        "model= smp.Unet(\n",
        "    encoder_name='resnet34',\n",
        "    encoder_weights=\"imagenet\",\n",
        "    encoder_depth=5,\n",
        "    in_channels=1,\n",
        "    classes=n_cls,\n",
        "    activation=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-7OrU3R-_Ry"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0YZT9Bz-_Rz"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0oUMzmq-_Rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd377aa-8ed8-4b18-8b01-1f41a0ca86e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training process...\n",
            "Epoch 1 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:31<00:00,  4.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:18<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 1 train process results: \n",
            "\n",
            "Train Time         -> 170.105 secs\n",
            "Train Loss         -> 0.044\n",
            "Train PA           -> 0.936\n",
            "Train IoU          -> 0.904\n",
            "Validation Loss    -> 0.010\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.952\n",
            "\n",
            "Loss decreased from inf to 0.010!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:30<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:18<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process results: \n",
            "\n",
            "Train Time         -> 169.041 secs\n",
            "Train Loss         -> 0.009\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.955\n",
            "Validation Loss    -> 0.012\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.939\n",
            "\n",
            "Loss did not decrease for 1 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:30<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:18<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process results: \n",
            "\n",
            "Train Time         -> 169.179 secs\n",
            "Train Loss         -> 0.006\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.968\n",
            "Validation Loss    -> 0.010\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.951\n",
            "\n",
            "Loss decreased from 0.012 to 0.010!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:30<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:18<00:00, 13.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process results: \n",
            "\n",
            "Train Time         -> 168.898 secs\n",
            "Train Loss         -> 0.007\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.963\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.949\n",
            "\n",
            "Loss decreased from 0.010 to 0.009!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:30<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:18<00:00, 13.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process results: \n",
            "\n",
            "Train Time         -> 169.520 secs\n",
            "Train Loss         -> 0.004\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.975\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.952\n",
            "\n",
            "Loss decreased from 0.009 to 0.009!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Train process is completed in 14.123 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history = train(model = model, tr_dl = tr_dl, val_dl = val_dl,\n",
        "                 loss_fn = loss_fn, opt = optimizer, device = device,\n",
        "                 epochs = EPOCHS, save_prefix = \"UnetResnet34\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "h39_tO9C-_R0"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"saved_models/liver_best_model.pt\")\n",
        "# inference(test_dl, model = model, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "volume_similarities,vol_sim_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D = calculate_results(model,test_dl )\n",
        "\n",
        "volume_similarities = calculate_group_averages(volume_similarities)\n",
        "vol_sim_abs = calculate_group_averages(vol_sim_abs)\n",
        "list_mioU3D = calculate_group_averages(list_mioU3D)\n",
        "list_dice3D = calculate_group_averages(list_dice3D)\n",
        "print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D)\n"
      ],
      "metadata": {
        "id": "CP86rc-t-_R0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587dadaa-fc69-4cd3-a0a4-786eb4b4cd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3874/3874 [01:04<00:00, 59.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIOU for the segmentation over the test set resulted in:\n",
            "0.898  +\\-  0.136\n",
            "\n",
            "The MIOU 3D for the segmentation over the test set resulted in:\n",
            "0.92  +\\-  0.034\n",
            "\n",
            "The Dicescore for the segmentation over the test set resulted in:\n",
            "0.938  +\\-  0.113\n",
            "\n",
            "The Dicescore 3D for the segmentation over the test set resulted in:\n",
            "0.957  +\\-  0.02\n",
            "\n",
            "The volume similarity for the segmentation over the test set resulted in:\n",
            "1.023  +\\-  0.008\n",
            "\n",
            "The volume similarity abs for the segmentation over the test set resulted in:\n",
            "0.975  +\\-  0.008\n",
            "\n",
            "\n",
            "The time needed for the segmentation of 8 3D images is:\n",
            "65.02 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resnet50 Unet++"
      ],
      "metadata": {
        "id": "GF0fHVtZVPov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v3CTcnbVPo9"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp, time\n",
        "import segmentation_models_pytorch as smp, time\n",
        "model = smp.UnetPlusPlus(\n",
        "    encoder_name='resnet50',\n",
        "    encoder_depth=5,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=n_cls,\n",
        "    activation=None,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17jy_qkAVPo9"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1amdCc4qVPo9"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd5Nf0lfVPo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879e7a0c-dfea-4a68-fd83-2e087b72170c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training process...\n",
            "Epoch 1 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [11:01<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [01:14<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 1 train process results: \n",
            "\n",
            "Train Time         -> 736.164 secs\n",
            "Train Loss         -> 0.058\n",
            "Train PA           -> 0.933\n",
            "Train IoU          -> 0.893\n",
            "Validation Loss    -> 0.011\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.947\n",
            "\n",
            "Loss decreased from inf to 0.011!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [11:01<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [01:14<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process results: \n",
            "\n",
            "Train Time         -> 736.123 secs\n",
            "Train Loss         -> 0.011\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.946\n",
            "Validation Loss    -> 0.010\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.938\n",
            "\n",
            "Loss decreased from 0.011 to 0.010!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [11:01<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [01:14<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process results: \n",
            "\n",
            "Train Time         -> 736.227 secs\n",
            "Train Loss         -> 0.008\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.959\n",
            "Validation Loss    -> 0.010\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.948\n",
            "\n",
            "Loss decreased from 0.010 to 0.010!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [11:02<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [01:14<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process results: \n",
            "\n",
            "Train Time         -> 736.951 secs\n",
            "Train Loss         -> 0.005\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.971\n",
            "Validation Loss    -> 0.008\n",
            "Validation PA      -> 0.988\n",
            "Validation IoU     -> 0.951\n",
            "\n",
            "Loss decreased from 0.010 to 0.008!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [11:02<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [01:14<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process results: \n",
            "\n",
            "Train Time         -> 737.007 secs\n",
            "Train Loss         -> 0.006\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.966\n",
            "Validation Loss    -> 0.013\n",
            "Validation PA      -> 0.986\n",
            "Validation IoU     -> 0.930\n",
            "\n",
            "Loss did not decrease for 1 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Train process is completed in 61.391 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history = train(model = model, tr_dl = tr_dl, val_dl = val_dl,\n",
        "                 loss_fn = loss_fn, opt = optimizer, device = device,\n",
        "                 epochs = EPOCHS, save_prefix = \"UnetppResnet50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XXfeSBHxVPo-"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"saved_models/liver_best_model.pt\")\n",
        "# inference(test_dl, model = model, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "volume_similarities,vol_sim_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D = calculate_results(model,test_dl )\n",
        "\n",
        "volume_similarities = calculate_group_averages(volume_similarities)\n",
        "vol_sim_abs = calculate_group_averages(vol_sim_abs)\n",
        "list_mioU3D = calculate_group_averages(list_mioU3D)\n",
        "list_dice3D = calculate_group_averages(list_dice3D)\n",
        "print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D)\n"
      ],
      "metadata": {
        "id": "ei7S0_G2VPo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c99f12-5168-46ef-b1a0-d2502c8bd800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3874/3874 [02:20<00:00, 27.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIOU for the segmentation over the test set resulted in:\n",
            "0.904  +\\-  0.148\n",
            "\n",
            "The MIOU 3D for the segmentation over the test set resulted in:\n",
            "0.923  +\\-  0.018\n",
            "\n",
            "The Dicescore for the segmentation over the test set resulted in:\n",
            "0.939  +\\-  0.131\n",
            "\n",
            "The Dicescore 3D for the segmentation over the test set resulted in:\n",
            "0.959  +\\-  0.01\n",
            "\n",
            "The volume similarity for the segmentation over the test set resulted in:\n",
            "1.008  +\\-  0.011\n",
            "\n",
            "The volume similarity abs for the segmentation over the test set resulted in:\n",
            "0.985  +\\-  0.01\n",
            "\n",
            "\n",
            "The time needed for the segmentation of 8 3D images is:\n",
            "140.73 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resnet34 Unet++"
      ],
      "metadata": {
        "id": "ayvbiOWJ_zLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQqIUhwU_zLe"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp, time\n",
        "import segmentation_models_pytorch as smp, time\n",
        "model = smp.UnetPlusPlus(\n",
        "    encoder_name='resnet34',\n",
        "    encoder_depth=5,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=n_cls,\n",
        "    activation=None,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWJoSNuQ_zLf"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCWooBeB_zLf"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zmDQ-7H_zLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942c4eaa-4e82-48a2-d91b-57c16786b16c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training process...\n",
            "Epoch 1 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [05:10<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:36<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 1 train process results: \n",
            "\n",
            "Train Time         -> 347.649 secs\n",
            "Train Loss         -> 0.026\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.915\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.947\n",
            "\n",
            "Loss decreased from inf to 0.009!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [05:10<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:36<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process results: \n",
            "\n",
            "Train Time         -> 347.512 secs\n",
            "Train Loss         -> 0.008\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.959\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.949\n",
            "\n",
            "Loss decreased from 0.009 to 0.009!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [05:10<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:36<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process results: \n",
            "\n",
            "Train Time         -> 347.416 secs\n",
            "Train Loss         -> 0.006\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.968\n",
            "Validation Loss    -> 0.008\n",
            "Validation PA      -> 0.988\n",
            "Validation IoU     -> 0.952\n",
            "\n",
            "Loss decreased from 0.009 to 0.008!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [05:10<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:37<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process results: \n",
            "\n",
            "Train Time         -> 347.898 secs\n",
            "Train Loss         -> 0.005\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.973\n",
            "Validation Loss    -> 0.011\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.945\n",
            "\n",
            "Loss did not decrease for 1 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [05:10<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:36<00:00,  6.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process results: \n",
            "\n",
            "Train Time         -> 347.517 secs\n",
            "Train Loss         -> 0.005\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.972\n",
            "Validation Loss    -> 0.008\n",
            "Validation PA      -> 0.988\n",
            "Validation IoU     -> 0.953\n",
            "\n",
            "Loss decreased from 0.011 to 0.008!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Train process is completed in 28.975 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history = train(model = model, tr_dl = tr_dl, val_dl = val_dl,\n",
        "                 loss_fn = loss_fn, opt = optimizer, device = device,\n",
        "                 epochs = EPOCHS, save_prefix = \"UnetppResnet34\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wwJR_wnN_zLg"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"saved_models/liver_best_model.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "volume_similarities,vol_sim_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D = calculate_results(model,test_dl )\n",
        "\n",
        "volume_similarities = calculate_group_averages(volume_similarities)\n",
        "vol_sim_abs = calculate_group_averages(vol_sim_abs)\n",
        "list_mioU3D = calculate_group_averages(list_mioU3D)\n",
        "list_dice3D = calculate_group_averages(list_dice3D)\n",
        "print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D)"
      ],
      "metadata": {
        "id": "Y-n1zKtr_zLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afedea64-b22e-4cc6-8822-a616b5e64378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3874/3874 [01:21<00:00, 47.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIOU for the segmentation over the test set resulted in:\n",
            "0.903  +\\-  0.145\n",
            "\n",
            "The MIOU 3D for the segmentation over the test set resulted in:\n",
            "0.924  +\\-  0.035\n",
            "\n",
            "The Dicescore for the segmentation over the test set resulted in:\n",
            "0.94  +\\-  0.122\n",
            "\n",
            "The Dicescore 3D for the segmentation over the test set resulted in:\n",
            "0.959  +\\-  0.021\n",
            "\n",
            "The volume similarity for the segmentation over the test set resulted in:\n",
            "1.002  +\\-  0.016\n",
            "\n",
            "The volume similarity abs for the segmentation over the test set resulted in:\n",
            "0.976  +\\-  0.017\n",
            "\n",
            "\n",
            "The time needed for the segmentation of 8 3D images is:\n",
            "81.86 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet mobile"
      ],
      "metadata": {
        "id": "jJ0vtPLlFOtC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW5hX070FOtN",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21ca665-8526-4045-cdd7-3f3fc25f918b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_mobilenetv3_large_100-427764d5.pth\" to /root/.cache/torch/hub/checkpoints/tf_mobilenetv3_large_100-427764d5.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 241MB/s]\n"
          ]
        }
      ],
      "source": [
        "import segmentation_models_pytorch as smp, time\n",
        "model= smp.Unet(\n",
        "    encoder_name='timm-mobilenetv3_large_100',\n",
        "    encoder_depth=5,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=n_cls,\n",
        "    activation=None,\n",
        "    )\n",
        "\n",
        "\n",
        "# Assuming you want to load the best model saved during training\n",
        "  # Make sure this matches the save_path used during training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load the best model\n",
        "# best_model_path = f\"/content/drive/MyDrive/saved_models/UnetMobile_best_model.pt\"\n",
        "# model = torch.load(best_model_path, map_location=torch.device(device))\n",
        "\n",
        "\n",
        "# Make sure to put the model in evaluation mode\n",
        "#model.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntscsljzFOtN"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7cEk9L_FOtO"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBkjyteiFOtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22166bfe-85ca-4c97-c635-4385cd50134c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training process...\n",
            "Epoch 1 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 726/727 [01:59<00:00,  6.18it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "100%|██████████| 727/727 [02:00<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:15<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 1 train process results: \n",
            "\n",
            "Train Time         -> 136.324 secs\n",
            "Train Loss         -> 0.049\n",
            "Train PA           -> 0.933\n",
            "Train IoU          -> 0.903\n",
            "Validation Loss    -> 0.011\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.945\n",
            "\n",
            "Loss decreased from inf to 0.011!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:00<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:16<00:00, 15.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process results: \n",
            "\n",
            "Train Time         -> 136.307 secs\n",
            "Train Loss         -> 0.007\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.964\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.949\n",
            "\n",
            "Loss decreased from 0.011 to 0.009!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:00<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:15<00:00, 15.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process results: \n",
            "\n",
            "Train Time         -> 136.067 secs\n",
            "Train Loss         -> 0.005\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.972\n",
            "Validation Loss    -> 0.013\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.935\n",
            "\n",
            "Loss did not decrease for 1 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [01:59<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:15<00:00, 15.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process results: \n",
            "\n",
            "Train Time         -> 135.918 secs\n",
            "Train Loss         -> 0.004\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.975\n",
            "Validation Loss    -> 0.009\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.950\n",
            "\n",
            "Loss decreased from 0.013 to 0.009!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:00<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:15<00:00, 15.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process results: \n",
            "\n",
            "Train Time         -> 136.138 secs\n",
            "Train Loss         -> 0.004\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.975\n",
            "Validation Loss    -> 0.010\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.952\n",
            "\n",
            "Loss did not decrease for 2 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Train process is completed in 11.352 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history = train(model = model, tr_dl = tr_dl, val_dl = val_dl,\n",
        "                 loss_fn = loss_fn, opt = optimizer, device = device,\n",
        "                 epochs = EPOCHS, save_prefix = \"UnetMobile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9szSI0MsFOtO"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"saved_models/liver_best_model.pt\")\n",
        "# inference(test_dl, model = model, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "volume_similarities,vol_sim_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D = calculate_results(model,test_dl )\n",
        "\n",
        "volume_similarities = calculate_group_averages(volume_similarities)\n",
        "vol_sim_abs = calculate_group_averages(vol_sim_abs)\n",
        "list_mioU3D = calculate_group_averages(list_mioU3D)\n",
        "list_dice3D = calculate_group_averages(list_dice3D)\n",
        "print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D)"
      ],
      "metadata": {
        "id": "5Jvkg9QAFOtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03142e9-3584-4300-d643-e7927917454c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3874/3874 [01:24<00:00, 45.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MIOU for the segmentation over the test set resulted in:\n",
            "0.901  +\\-  0.128\n",
            "\n",
            "The MIOU 3D for the segmentation over the test set resulted in:\n",
            "0.924  +\\-  0.025\n",
            "\n",
            "The Dicescore for the segmentation over the test set resulted in:\n",
            "0.941  +\\-  0.107\n",
            "\n",
            "The Dicescore 3D for the segmentation over the test set resulted in:\n",
            "0.96  +\\-  0.014\n",
            "\n",
            "The volume similarity for the segmentation over the test set resulted in:\n",
            "1.02  +\\-  0.011\n",
            "\n",
            "The volume similarity abs for the segmentation over the test set resulted in:\n",
            "0.974  +\\-  0.012\n",
            "\n",
            "\n",
            "The time needed for the segmentation of 8 3D images is:\n",
            "85.04 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet++ mobile"
      ],
      "metadata": {
        "id": "FwuiKSp-TjFY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqHgTLz0TjFm"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp, time\n",
        "model= smp.UnetPlusPlus(\n",
        "    encoder_name='timm-mobilenetv3_large_100',\n",
        "    encoder_depth=5,\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=1,\n",
        "    classes=n_cls,\n",
        "    activation=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE9ImBJrTjFn"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = 3e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5VYvl4KTjFn"
      },
      "outputs": [],
      "source": [
        "import json, os, torch, cv2, random, numpy as np, albumentations as A, nibabel as nib\n",
        "from matplotlib import pyplot as plt; from glob import glob;\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2; from PIL import Image\n",
        "from torchvision import transforms as tfs\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnzNixouTjFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6097efd4-ad86-4370-bea8-7ea7be30d3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training process...\n",
            "Epoch 1 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:50<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:21<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 1 train process results: \n",
            "\n",
            "Train Time         -> 191.466 secs\n",
            "Train Loss         -> 0.032\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.911\n",
            "Validation Loss    -> 0.016\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.931\n",
            "\n",
            "Loss decreased from inf to 0.016!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:49<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:20<00:00, 11.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 2 train process results: \n",
            "\n",
            "Train Time         -> 190.618 secs\n",
            "Train Loss         -> 0.007\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.964\n",
            "Validation Loss    -> 0.011\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.944\n",
            "\n",
            "Loss decreased from 0.016 to 0.011!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:49<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:21<00:00, 11.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 3 train process results: \n",
            "\n",
            "Train Time         -> 190.803 secs\n",
            "Train Loss         -> 0.005\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.972\n",
            "Validation Loss    -> 0.010\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.954\n",
            "\n",
            "Loss decreased from 0.011 to 0.010!\n",
            "Saving the model with the best loss value...\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:49<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:20<00:00, 11.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 4 train process results: \n",
            "\n",
            "Train Time         -> 190.428 secs\n",
            "Train Loss         -> 0.004\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.976\n",
            "Validation Loss    -> 0.011\n",
            "Validation PA      -> 0.987\n",
            "Validation IoU     -> 0.949\n",
            "\n",
            "Loss did not decrease for 1 epoch(s)!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 727/727 [02:49<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 validation process is started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:20<00:00, 11.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train process is completed.\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Epoch 5 train process results: \n",
            "\n",
            "Train Time         -> 190.609 secs\n",
            "Train Loss         -> 0.005\n",
            "Train PA           -> 0.938\n",
            "Train IoU          -> 0.974\n",
            "Validation Loss    -> 0.008\n",
            "Validation PA      -> 0.988\n",
            "Validation IoU     -> 0.956\n",
            "\n",
            "Loss decreased from 0.011 to 0.008!\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Train process is completed in 15.903 minutes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "history = train(model = model, tr_dl = tr_dl, val_dl = val_dl,\n",
        "                 loss_fn = loss_fn, opt = optimizer, device = device,\n",
        "                 epochs = EPOCHS, save_prefix = \"UnetppMobile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ru4zyPZaTjFo"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"saved_models/liver_best_model.pt\")\n",
        "# inference(test_dl, model = model, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "volume_similarities,vol_sim_abs, miou_test, dicescores, execution_time, list_mioU3D,list_dice3D = calculate_results(model,test_dl )\n",
        "\n",
        "volume_similarities = calculate_group_averages(volume_similarities)\n",
        "vol_sim_abs = calculate_group_averages(vol_sim_abs)\n",
        "list_mioU3D = calculate_group_averages(list_mioU3D)\n",
        "list_dice3D = calculate_group_averages(list_dice3D)\n",
        "print_results(miou_test,dicescores,volume_similarities,vol_sim_abs,execution_time,list_mioU3D,list_dice3D)"
      ],
      "metadata": {
        "id": "PCOMwqXNTjFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4f4474-3a14-4149-9c43-afb76bb17624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 3478/3874 [01:22<00:10, 36.82it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}